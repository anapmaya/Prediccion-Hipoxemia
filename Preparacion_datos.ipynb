{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f273b633",
   "metadata": {},
   "source": [
    "## Preparación de los datos para entrenar los modelos clásicos, creación de ventanas deslizantes, asignacion de etiquetas\n",
    "\n",
    "**Voy a crear ventanas de 1 minuto, es decir 6 muestras. Quiero predecir si habrá hipoxemia en los próximos 5 minutos, considerando hipoxemia un valor de SPO2 < 90% por al menos un minuto.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cbec70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import vitaldb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm  #barra de progreso\n",
    "import pyarrow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551db00c",
   "metadata": {},
   "source": [
    "Después de la reunión con los médicos anestesiólogos, se realizaron cambios en las columnas que había elegido inicialmente para el dataset. Voy a ejecutar la preparación de los datos para el dataset ya filtrado, limpio y completo que tengo listo con las variables definitivas después de la validación mencionada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105209ff",
   "metadata": {},
   "source": [
    "#### Plan a seguir:\n",
    "\n",
    "1. Definir constantes: intervalo de muestreo, tamaño ventana, horizonte, duración mínima de evento (en pasos).\n",
    "\n",
    "2. Agrupar por caseid. Para cada cirugía:\n",
    "\n",
    "- Asegurar orden temporal de las filas y calcular sample_idx (0,1,2...) si no existe.\n",
    "\n",
    "- Detectar inicios de runs de hipoxemia (run_start) de longitud ≥ 6 pasos.\n",
    "\n",
    "- Construir ventanas que terminan en cada índice i (ventana de 6 muestras: i-5..i). Generamos ventanas con stride = 1 (una ventana por paso) siempre que exista el horizonte futuro completo (descartamos ventanas cerca del final sin horizonte completo).\n",
    "\n",
    "- Etiquetar cada ventana: 1 si dentro de los próximos 30 pasos existe al menos UN run continuo de ≥6 muestras < 90; 0 en caso contrario.\n",
    "\n",
    "- Extraer features por ventana (dos opciones):\n",
    "\n",
    "    - A) Features agregadas (para modelos clásicos): media, std, min, max, último valor, pendiente en la ventana, % muestras < 90 (para SpO₂), etc. → una fila por ventana.\n",
    "\n",
    "    - B) Ventanas crudas (para deep learning): guardar la matriz (6, n_dyn_features) y el vector estático asociado (age, asa, ane_type codificada, etc.) y la etiqueta.\n",
    "\n",
    "3. Concatenar resultados de todas las cirugías en un windows_df (features agregadas + etiqueta + caseid + time_end) y, opcionalmente, guardar las ventanas crudas en archivos .npz o TFRecords.\n",
    "\n",
    "4. Hacer split por caseid (ej. train/val/test 70/15/15) — nunca mezclar ventanas de la misma cirugía en conjuntos diferentes.\n",
    "\n",
    "5. Normalización / scaling: fit del scaler en train y aplicar a val/test. Alternativa clínica: normalización por cirugía o baseline dinámico (ver notas).\n",
    "\n",
    "6. Guardar dataset procesado en parquet / np.savez para entrenamiento posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3430890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: generar ventanas de 1 min y labels con horizonte 5 min (SpO2 < 90% sostenida 60s)\n",
    "\n",
    "# ----------------------- PARÁMETROS -----------------------\n",
    "SAMPLING_INTERVAL = 10                      # segundos entre muestras\n",
    "WINDOW_SEC = 60\n",
    "HORIZON_SEC = 5 * 60\n",
    "EVENT_SEC = 60\n",
    "\n",
    "window_steps = int(WINDOW_SEC // SAMPLING_INTERVAL)   # = 6\n",
    "horizon_steps = int(HORIZON_SEC // SAMPLING_INTERVAL) # = 30\n",
    "event_steps = int(EVENT_SEC // SAMPLING_INTERVAL)     # = 6\n",
    "\n",
    "SPO2_COL = 'Solar8000/PLETH_SPO2'\n",
    "DYN_PREFIX = 'Solar8000/'\n",
    "ID_COL = 'caseid'\n",
    "\n",
    "# Columnas estáticas\n",
    "STATIC_COLS = [\n",
    "    'age','sex','height','weight','bmi','asa','emop',\n",
    "    'approach','position', 'dltubesize', \n",
    "    'preop_htn', 'preop_dm', 'preop_ecg', 'preop_pft', 'preop_hb',\n",
    "    'intraop_ppf', 'intraop_rbc', 'intraop_ffp',\n",
    "    'intraop_mdz', 'intraop_ftn', 'intraop_rocu', 'intraop_vecu', \n",
    "    'intraop_eph', 'intraop_phe', 'intraop_epi', 'intraop_ca',\n",
    "    'dur_op_seg', 'dur_anest_seg', 'dur_case_seg'\n",
    "]\n",
    "\n",
    "# Carpeta para guardar artefactos\n",
    "OUT_DIR = 'windows_output'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------- FUNCIONES UTILITARIAS -----------------------\n",
    "def ensure_sample_index(group, sampling_interval=SAMPLING_INTERVAL):\n",
    "    \"\"\"Si no hay columna de tiempo, crear sample_idx y time_sec.\"\"\"\n",
    "    group = group.copy().reset_index(drop=True)\n",
    "    if 'sample_idx' not in group.columns:\n",
    "        group['sample_idx'] = np.arange(len(group))\n",
    "    if 'time_sec' not in group.columns:\n",
    "        group['time_sec'] = group['sample_idx'] * sampling_interval\n",
    "    return group\n",
    "\n",
    "def compute_run_start_bool(bools, min_run_len=event_steps):\n",
    "    \"\"\"Dada una máscara booleana (True = SpO2 < 90), devuelve array run_start_full de longitud N\n",
    "       con 1 donde comienza una run de longitud >= min_run_len.\"\"\"\n",
    "    N = len(bools)\n",
    "    if N < min_run_len:\n",
    "        return np.zeros(N, dtype=int)\n",
    "    conv = np.convolve(bools.astype(int), np.ones(min_run_len, dtype=int), mode='valid')\n",
    "    starts = (conv == min_run_len).astype(int)   # length = N - min_run_len + 1\n",
    "    run_start_full = np.zeros(N, dtype=int)\n",
    "    run_start_full[:len(starts)] = starts\n",
    "    return run_start_full\n",
    "\n",
    "def extract_aggregated_features(window_df, dyn_cols):\n",
    "    \"\"\"Devuelve un dict con features agregadas para la ventana (por cada dyn_col).\"\"\"\n",
    "    feats = {}\n",
    "    x = window_df[dyn_cols].values  # shape (window_steps, n_dyn)\n",
    "    steps = x.shape[0]\n",
    "    idx = np.arange(steps)\n",
    "    for j, col in enumerate(dyn_cols):\n",
    "        vals = x[:, j]\n",
    "        base_name = col.split('/')[-1]  # e.g. PLETH_SPO2\n",
    "        feats[f'{base_name}_mean'] = float(np.nanmean(vals))\n",
    "        feats[f'{base_name}_std']  = float(np.nanstd(vals))\n",
    "        feats[f'{base_name}_min']  = float(np.nanmin(vals))\n",
    "        feats[f'{base_name}_max']  = float(np.nanmax(vals))\n",
    "        feats[f'{base_name}_last'] = float(vals[-1])\n",
    "        # slope (pendiente) por fit lineal simple\n",
    "        if np.all(np.isfinite(vals)):\n",
    "            try:\n",
    "                slope = np.polyfit(idx, vals, 1)[0]\n",
    "            except np.RankWarning:\n",
    "                slope = 0.0\n",
    "        else:\n",
    "            slope = 0.0\n",
    "        feats[f'{base_name}_slope'] = float(slope)\n",
    "        # para SpO2: % tiempo por debajo de 90 en la ventana\n",
    "        if base_name.upper().find('SPO2') >= 0 or base_name.upper().find('PLETH') >= 0:\n",
    "            feats[f'{base_name}_pct_below_90'] = float(np.mean(vals < 90.0))\n",
    "    return feats\n",
    "\n",
    "# ----------------------- PROCESAR CADA CIRUGÍA -----------------------\n",
    "def process_case_windows(group, dyn_cols, static_cols=STATIC_COLS,\n",
    "                         window_steps=window_steps, horizon_steps=horizon_steps,\n",
    "                         event_steps=event_steps, spo2_col=SPO2_COL):\n",
    "    \"\"\"\n",
    "    Procesa una cirugía (group) y devuelve lista de dicts:\n",
    "      - features agregadas por ventana\n",
    "      - label (0/1)\n",
    "      - caseid, time_end (segundos)\n",
    "    \"\"\"\n",
    "    group = ensure_sample_index(group)\n",
    "    N = len(group)\n",
    "    results = []\n",
    "    if N < window_steps + horizon_steps:\n",
    "        # cirugía demasiado corta para crear ventanas con horizonte completo -> saltar\n",
    "        return results\n",
    "\n",
    "    # arrays veloces\n",
    "    spo2 = group[spo2_col].values\n",
    "    is_low = (spo2 < 90.0)\n",
    "    run_start = compute_run_start_bool(is_low, min_run_len=event_steps)  # length N\n",
    "    # prefix sum para queries rango de run_start\n",
    "    prefix = np.concatenate(([0], run_start.cumsum()))  # length N+1, prefix[k] = sum run_start[:k]\n",
    "\n",
    "    # índices donde la ventana puede terminar: i from window_steps-1 to N-1-horizon_steps (inclusive)\n",
    "    i_start = window_steps - 1\n",
    "    i_end = N - 1 - horizon_steps\n",
    "    window_ends = np.arange(i_start, i_end + 1)\n",
    "\n",
    "    # calc a,b arrays: posibles inicios de run que caben dentro del horizonte\n",
    "    a = window_ends + 1\n",
    "    b = window_ends + horizon_steps - event_steps + 1\n",
    "    # limitar b al máximo índice válido de run_start (N - event_steps)\n",
    "    max_start_index = max(0, N - event_steps)\n",
    "    b = np.minimum(b, max_start_index)\n",
    "\n",
    "    dyn = group[dyn_cols]  # pandas slice\n",
    "\n",
    "    for i_idx, i in enumerate(window_ends):\n",
    "        ai = int(a[i_idx])\n",
    "        bi = int(b[i_idx])\n",
    "        label = 0\n",
    "        if bi >= ai:\n",
    "            # número de run_starts en [ai, bi] = prefix[bi+1] - prefix[ai]\n",
    "            nstarts = int(prefix[bi + 1] - prefix[ai])\n",
    "            if nstarts > 0:\n",
    "                label = 1\n",
    "        # extraer ventana de señales para features\n",
    "        win_start = i - (window_steps - 1)\n",
    "        win_end = i  # inclusive\n",
    "        window_df = dyn.iloc[win_start:win_end + 1]\n",
    "        feats = extract_aggregated_features(window_df, dyn_cols)\n",
    "        # añadir features estáticos (tomados del primer renglón de la cirugía)\n",
    "        static_dict = {}\n",
    "        for s in static_cols:\n",
    "            if s in group.columns:\n",
    "                static_dict[s] = group[s].iloc[0]\n",
    "            else:\n",
    "                static_dict[s] = np.nan\n",
    "        # meta\n",
    "        meta = {\n",
    "            'caseid': group[ID_COL].iloc[0],\n",
    "            'window_end_idx': int(i),\n",
    "            'window_end_time_sec': float(group['time_sec'].iloc[i]),\n",
    "            'label_hypoxemia': int(label)\n",
    "        }\n",
    "        row = {}\n",
    "        row.update(meta)\n",
    "        row.update(static_dict)\n",
    "        row.update(feats)\n",
    "        results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "# ----------------------- PIPELINE PRINCIPAL -----------------------\n",
    "def build_windows_dataframe(df, dyn_prefix=DYN_PREFIX, static_cols=STATIC_COLS,\n",
    "                            save_parquet=True, parquet_path=os.path.join(OUT_DIR, 'windows_aggregated2.parquet')):\n",
    "    dyn_cols = [c for c in df.columns if c.startswith(dyn_prefix)]\n",
    "    out_rows = []\n",
    "    grouped = df.groupby(ID_COL)\n",
    "    for caseid, group in tqdm(grouped, total=df[ID_COL].nunique(), desc='Procesando casos'):\n",
    "        rows = process_case_windows(group, dyn_cols, static_cols)\n",
    "        if rows:\n",
    "            out_rows.extend(rows)\n",
    "    windows_df = pd.DataFrame(out_rows)\n",
    "    if save_parquet:\n",
    "        windows_df.to_parquet(parquet_path, index=False)\n",
    "        print(f'Saved windows aggregated to {parquet_path} (n_windows={len(windows_df)})')\n",
    "    return windows_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11046c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando casos: 100%|██████████| 910/910 [13:18<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved windows aggregated to windows_output/windows_aggregated2.parquet (n_windows=1043478)\n",
      "(1043478, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>window_end_idx</th>\n",
       "      <th>window_end_time_sec</th>\n",
       "      <th>label_hypoxemia</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>asa</th>\n",
       "      <th>...</th>\n",
       "      <th>VENT_TV_min</th>\n",
       "      <th>VENT_TV_max</th>\n",
       "      <th>VENT_TV_last</th>\n",
       "      <th>VENT_TV_slope</th>\n",
       "      <th>VENT_RR_mean</th>\n",
       "      <th>VENT_RR_std</th>\n",
       "      <th>VENT_RR_min</th>\n",
       "      <th>VENT_RR_max</th>\n",
       "      <th>VENT_RR_last</th>\n",
       "      <th>VENT_RR_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>9.197718e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>9.197718e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>9.197718e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>9.197718e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>9.197718e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  window_end_idx  window_end_time_sec  label_hypoxemia  age sex  \\\n",
       "0       7               5                 50.0                1   52   F   \n",
       "1       7               6                 60.0                1   52   F   \n",
       "2       7               7                 70.0                1   52   F   \n",
       "3       7               8                 80.0                1   52   F   \n",
       "4       7               9                 90.0                1   52   F   \n",
       "\n",
       "   height  weight   bmi  asa  ...  VENT_TV_min VENT_TV_max VENT_TV_last  \\\n",
       "0   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "1   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "2   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "3   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "4   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "\n",
       "  VENT_TV_slope  VENT_RR_mean  VENT_RR_std VENT_RR_min VENT_RR_max  \\\n",
       "0  9.197718e-14           0.0          0.0         0.0         0.0   \n",
       "1  9.197718e-14           0.0          0.0         0.0         0.0   \n",
       "2  9.197718e-14           0.0          0.0         0.0         0.0   \n",
       "3  9.197718e-14           0.0          0.0         0.0         0.0   \n",
       "4  9.197718e-14           0.0          0.0         0.0         0.0   \n",
       "\n",
       "   VENT_RR_last  VENT_RR_slope  \n",
       "0           0.0            0.0  \n",
       "1           0.0            0.0  \n",
       "2           0.0            0.0  \n",
       "3           0.0            0.0  \n",
       "4           0.0            0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------- EJECUCIÓN -----------------------\n",
    "df = pd.read_csv('dataset_fuente_completo2.csv')\n",
    "windows_df2 = build_windows_dataframe(df)\n",
    "print(windows_df2.shape)\n",
    "windows_df2.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad372c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1043478 entries, 0 to 1043477\n",
      "Columns: 101 entries, caseid to VENT_RR_slope\n",
      "dtypes: float64(76), int64(19), object(6)\n",
      "memory usage: 804.1+ MB\n"
     ]
    }
   ],
   "source": [
    "windows_df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e7b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_hypoxemia\n",
      "0    0.967905\n",
      "1    0.032095\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#VERIFICACIÓN RÁPIDA INICIAL DE HIPOXEMIA\n",
    "print(windows_df['label_hypoxemia'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2890db0",
   "metadata": {},
   "source": [
    "Ya tengo mis datos preparados, con ventanas deslizantes que tienen en cada fila los datos corresponientes a una ventana de 1 minuto y una etiqueta que dice si habrá hipoxemia en los próximos 5 minutos. Quedó almacenado en el archivo `windows_aggregated2.parquet`\n",
    "\n",
    "Tengo un dataset con un desbalanceo grande: 3.2% positivos, 96,8% negativos. Es un desbalance habitual para casos médicos.\n",
    "\n",
    "Con estos datos procedo a continuar con la fase de entrenamiento de modelos clásicos: Regresión Logística, Random Forest, XGBoost, Gradient Boosting (ver notebook `modelos_clasicos.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e3da5",
   "metadata": {},
   "source": [
    "## Nueva versión de dataset, con cambios en la cantidad de muestras por ventana\n",
    "\n",
    "He veido trabajando con ventanas de 1 minuto (6 muestras) para predecir hipoxemia en los próximos 5 minutos. Quiero ampliar mis ventanas y ver si esto se refleja en alguna mejora del modelo. Lo voy a hacer en dos versiones: ventanas de 5 minutos y ventanas de 10 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c78b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: generar VENTANAS DE 5 MINUTOS y labels con horizonte 5 min (SpO2 < 90% sostenida 60s)\n",
    "\n",
    "# ----------------------- PARÁMETROS -----------------------\n",
    "SAMPLING_INTERVAL = 10                      # segundos entre muestras\n",
    "WINDOW_SEC = 300\n",
    "HORIZON_SEC = 5 * 60\n",
    "EVENT_SEC = 60\n",
    "\n",
    "window_steps = int(WINDOW_SEC // SAMPLING_INTERVAL)   # = 6\n",
    "horizon_steps = int(HORIZON_SEC // SAMPLING_INTERVAL) # = 30\n",
    "event_steps = int(EVENT_SEC // SAMPLING_INTERVAL)     # = 6\n",
    "\n",
    "SPO2_COL = 'Solar8000/PLETH_SPO2'\n",
    "DYN_PREFIX = 'Solar8000/'\n",
    "ID_COL = 'caseid'\n",
    "\n",
    "# Columnas estáticas\n",
    "STATIC_COLS = [\n",
    "    'age','sex','height','weight','bmi','asa','emop',\n",
    "    'approach','position', 'dltubesize', \n",
    "    'preop_htn', 'preop_dm', 'preop_ecg', 'preop_pft', 'preop_hb',\n",
    "    'intraop_ppf', 'intraop_rbc', 'intraop_ffp',\n",
    "    'intraop_mdz', 'intraop_ftn', 'intraop_rocu', 'intraop_vecu', \n",
    "    'intraop_eph', 'intraop_phe', 'intraop_epi', 'intraop_ca',\n",
    "    'dur_op_seg', 'dur_anest_seg', 'dur_case_seg'\n",
    "]\n",
    "\n",
    "# Carpeta para guardar artefactos\n",
    "OUT_DIR = 'windows_output'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------- FUNCIONES UTILITARIAS -----------------------\n",
    "def ensure_sample_index(group, sampling_interval=SAMPLING_INTERVAL):\n",
    "    \"\"\"Si no hay columna de tiempo, crear sample_idx y time_sec.\"\"\"\n",
    "    group = group.copy().reset_index(drop=True)\n",
    "    if 'sample_idx' not in group.columns:\n",
    "        group['sample_idx'] = np.arange(len(group))\n",
    "    if 'time_sec' not in group.columns:\n",
    "        group['time_sec'] = group['sample_idx'] * sampling_interval\n",
    "    return group\n",
    "\n",
    "def compute_run_start_bool(bools, min_run_len=event_steps):\n",
    "    \"\"\"Dada una máscara booleana (True = SpO2 < 90), devuelve array run_start_full de longitud N\n",
    "       con 1 donde comienza una run de longitud >= min_run_len.\"\"\"\n",
    "    N = len(bools)\n",
    "    if N < min_run_len:\n",
    "        return np.zeros(N, dtype=int)\n",
    "    conv = np.convolve(bools.astype(int), np.ones(min_run_len, dtype=int), mode='valid')\n",
    "    starts = (conv == min_run_len).astype(int)   # length = N - min_run_len + 1\n",
    "    run_start_full = np.zeros(N, dtype=int)\n",
    "    run_start_full[:len(starts)] = starts\n",
    "    return run_start_full\n",
    "\n",
    "def extract_aggregated_features(window_df, dyn_cols):\n",
    "    \"\"\"Devuelve un dict con features agregadas para la ventana (por cada dyn_col).\"\"\"\n",
    "    feats = {}\n",
    "    x = window_df[dyn_cols].values  # shape (window_steps, n_dyn)\n",
    "    steps = x.shape[0]\n",
    "    idx = np.arange(steps)\n",
    "    for j, col in enumerate(dyn_cols):\n",
    "        vals = x[:, j]\n",
    "        base_name = col.split('/')[-1]  # e.g. PLETH_SPO2\n",
    "        feats[f'{base_name}_mean'] = float(np.nanmean(vals))\n",
    "        feats[f'{base_name}_std']  = float(np.nanstd(vals))\n",
    "        feats[f'{base_name}_min']  = float(np.nanmin(vals))\n",
    "        feats[f'{base_name}_max']  = float(np.nanmax(vals))\n",
    "        feats[f'{base_name}_last'] = float(vals[-1])\n",
    "        # slope (pendiente) por fit lineal simple\n",
    "        if np.all(np.isfinite(vals)):\n",
    "            try:\n",
    "                slope = np.polyfit(idx, vals, 1)[0]\n",
    "            except np.RankWarning:\n",
    "                slope = 0.0\n",
    "        else:\n",
    "            slope = 0.0\n",
    "        feats[f'{base_name}_slope'] = float(slope)\n",
    "        # para SpO2: % tiempo por debajo de 90 en la ventana\n",
    "        if base_name.upper().find('SPO2') >= 0 or base_name.upper().find('PLETH') >= 0:\n",
    "            feats[f'{base_name}_pct_below_90'] = float(np.mean(vals < 90.0))\n",
    "    return feats\n",
    "\n",
    "# ----------------------- PROCESAR CADA CIRUGÍA -----------------------\n",
    "def process_case_windows(group, dyn_cols, static_cols=STATIC_COLS,\n",
    "                         window_steps=window_steps, horizon_steps=horizon_steps,\n",
    "                         event_steps=event_steps, spo2_col=SPO2_COL):\n",
    "    \"\"\"\n",
    "    Procesa una cirugía (group) y devuelve lista de dicts:\n",
    "      - features agregadas por ventana\n",
    "      - label (0/1)\n",
    "      - caseid, time_end (segundos)\n",
    "    \"\"\"\n",
    "    group = ensure_sample_index(group)\n",
    "    N = len(group)\n",
    "    results = []\n",
    "    if N < window_steps + horizon_steps:\n",
    "        # cirugía demasiado corta para crear ventanas con horizonte completo -> saltar\n",
    "        return results\n",
    "\n",
    "    # arrays veloces\n",
    "    spo2 = group[spo2_col].values\n",
    "    is_low = (spo2 < 90.0)\n",
    "    run_start = compute_run_start_bool(is_low, min_run_len=event_steps)  # length N\n",
    "    # prefix sum para queries rango de run_start\n",
    "    prefix = np.concatenate(([0], run_start.cumsum()))  # length N+1, prefix[k] = sum run_start[:k]\n",
    "\n",
    "    # índices donde la ventana puede terminar: i from window_steps-1 to N-1-horizon_steps (inclusive)\n",
    "    i_start = window_steps - 1\n",
    "    i_end = N - 1 - horizon_steps\n",
    "    window_ends = np.arange(i_start, i_end + 1)\n",
    "\n",
    "    # calc a,b arrays: posibles inicios de run que caben dentro del horizonte\n",
    "    a = window_ends + 1\n",
    "    b = window_ends + horizon_steps - event_steps + 1\n",
    "    # limitar b al máximo índice válido de run_start (N - event_steps)\n",
    "    max_start_index = max(0, N - event_steps)\n",
    "    b = np.minimum(b, max_start_index)\n",
    "\n",
    "    dyn = group[dyn_cols]  # pandas slice\n",
    "\n",
    "    for i_idx, i in enumerate(window_ends):\n",
    "        ai = int(a[i_idx])\n",
    "        bi = int(b[i_idx])\n",
    "        label = 0\n",
    "        if bi >= ai:\n",
    "            # número de run_starts en [ai, bi] = prefix[bi+1] - prefix[ai]\n",
    "            nstarts = int(prefix[bi + 1] - prefix[ai])\n",
    "            if nstarts > 0:\n",
    "                label = 1\n",
    "        # extraer ventana de señales para features\n",
    "        win_start = i - (window_steps - 1)\n",
    "        win_end = i  # inclusive\n",
    "        window_df = dyn.iloc[win_start:win_end + 1]\n",
    "        feats = extract_aggregated_features(window_df, dyn_cols)\n",
    "        # añadir features estáticos (tomados del primer renglón de la cirugía)\n",
    "        static_dict = {}\n",
    "        for s in static_cols:\n",
    "            if s in group.columns:\n",
    "                static_dict[s] = group[s].iloc[0]\n",
    "            else:\n",
    "                static_dict[s] = np.nan\n",
    "        # meta\n",
    "        meta = {\n",
    "            'caseid': group[ID_COL].iloc[0],\n",
    "            'window_end_idx': int(i),\n",
    "            'window_end_time_sec': float(group['time_sec'].iloc[i]),\n",
    "            'label_hypoxemia': int(label)\n",
    "        }\n",
    "        row = {}\n",
    "        row.update(meta)\n",
    "        row.update(static_dict)\n",
    "        row.update(feats)\n",
    "        results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "# ----------------------- PIPELINE PRINCIPAL -----------------------\n",
    "def build_windows_dataframe(df, dyn_prefix=DYN_PREFIX, static_cols=STATIC_COLS,\n",
    "                            save_parquet=True, parquet_path=os.path.join(OUT_DIR, 'windows_aggregated_5min.parquet')):\n",
    "    dyn_cols = [c for c in df.columns if c.startswith(dyn_prefix)]\n",
    "    out_rows = []\n",
    "    grouped = df.groupby(ID_COL)\n",
    "    for caseid, group in tqdm(grouped, total=df[ID_COL].nunique(), desc='Procesando casos'):\n",
    "        rows = process_case_windows(group, dyn_cols, static_cols)\n",
    "        if rows:\n",
    "            out_rows.extend(rows)\n",
    "    windows_df = pd.DataFrame(out_rows)\n",
    "    if save_parquet:\n",
    "        windows_df.to_parquet(parquet_path, index=False)\n",
    "        print(f'Saved windows aggregated to {parquet_path} (n_windows={len(windows_df)})')\n",
    "    return windows_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a153930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando casos: 100%|██████████| 910/910 [13:01<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved windows aggregated to windows_output/windows_aggregated_5min.parquet (n_windows=1021638)\n",
      "(1021638, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>window_end_idx</th>\n",
       "      <th>window_end_time_sec</th>\n",
       "      <th>label_hypoxemia</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>asa</th>\n",
       "      <th>...</th>\n",
       "      <th>VENT_TV_min</th>\n",
       "      <th>VENT_TV_max</th>\n",
       "      <th>VENT_TV_last</th>\n",
       "      <th>VENT_TV_slope</th>\n",
       "      <th>VENT_RR_mean</th>\n",
       "      <th>VENT_RR_std</th>\n",
       "      <th>VENT_RR_min</th>\n",
       "      <th>VENT_RR_max</th>\n",
       "      <th>VENT_RR_last</th>\n",
       "      <th>VENT_RR_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  window_end_idx  window_end_time_sec  label_hypoxemia  age sex  \\\n",
       "0       7              29                290.0                0   52   F   \n",
       "1       7              30                300.0                0   52   F   \n",
       "2       7              31                310.0                0   52   F   \n",
       "3       7              32                320.0                0   52   F   \n",
       "4       7              33                330.0                0   52   F   \n",
       "\n",
       "   height  weight   bmi  asa  ...  VENT_TV_min VENT_TV_max VENT_TV_last  \\\n",
       "0   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "1   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "2   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "3   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "4   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "\n",
       "  VENT_TV_slope  VENT_RR_mean  VENT_RR_std VENT_RR_min VENT_RR_max  \\\n",
       "0           0.0           0.0          0.0         0.0         0.0   \n",
       "1           0.0           0.0          0.0         0.0         0.0   \n",
       "2           0.0           0.0          0.0         0.0         0.0   \n",
       "3           0.0           0.0          0.0         0.0         0.0   \n",
       "4           0.0           0.0          0.0         0.0         0.0   \n",
       "\n",
       "   VENT_RR_last  VENT_RR_slope  \n",
       "0           0.0            0.0  \n",
       "1           0.0            0.0  \n",
       "2           0.0            0.0  \n",
       "3           0.0            0.0  \n",
       "4           0.0            0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------- EJECUCIÓN -----------------------\n",
    "df = pd.read_csv('dataset_fuente_completo2.csv')\n",
    "windows_df3 = build_windows_dataframe(df)\n",
    "print(windows_df3.shape)\n",
    "windows_df3.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e208aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1021638 entries, 0 to 1021637\n",
      "Columns: 101 entries, caseid to VENT_RR_slope\n",
      "dtypes: float64(76), int64(19), object(6)\n",
      "memory usage: 787.2+ MB\n"
     ]
    }
   ],
   "source": [
    "windows_df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56fdd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_hypoxemia\n",
      "0    0.968042\n",
      "1    0.031958\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#VERIFICACIÓN RÁPIDA INICIAL DE HIPOXEMIA\n",
    "print(windows_df3['label_hypoxemia'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7a09a",
   "metadata": {},
   "source": [
    "El dataset con ventanas que contienen la información de 5 minutos de muestras quedó almaceado en el archivo `windows_aggregated_5min.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f716a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: generar VENTANAS DE 10 MINUTOS y labels con horizonte 10 min (SpO2 < 90% sostenida 60s)\n",
    "\n",
    "# ----------------------- PARÁMETROS -----------------------\n",
    "SAMPLING_INTERVAL = 10                      # segundos entre muestras\n",
    "WINDOW_SEC = 600\n",
    "HORIZON_SEC = 5 * 60\n",
    "EVENT_SEC = 60\n",
    "\n",
    "window_steps = int(WINDOW_SEC // SAMPLING_INTERVAL)   # = 6\n",
    "horizon_steps = int(HORIZON_SEC // SAMPLING_INTERVAL) # = 30\n",
    "event_steps = int(EVENT_SEC // SAMPLING_INTERVAL)     # = 6\n",
    "\n",
    "SPO2_COL = 'Solar8000/PLETH_SPO2'\n",
    "DYN_PREFIX = 'Solar8000/'\n",
    "ID_COL = 'caseid'\n",
    "\n",
    "# Columnas estáticas\n",
    "STATIC_COLS = [\n",
    "    'age','sex','height','weight','bmi','asa','emop',\n",
    "    'approach','position', 'dltubesize', \n",
    "    'preop_htn', 'preop_dm', 'preop_ecg', 'preop_pft', 'preop_hb',\n",
    "    'intraop_ppf', 'intraop_rbc', 'intraop_ffp',\n",
    "    'intraop_mdz', 'intraop_ftn', 'intraop_rocu', 'intraop_vecu', \n",
    "    'intraop_eph', 'intraop_phe', 'intraop_epi', 'intraop_ca',\n",
    "    'dur_op_seg', 'dur_anest_seg', 'dur_case_seg'\n",
    "]\n",
    "\n",
    "# Carpeta para guardar artefactos\n",
    "OUT_DIR = 'windows_output'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------- FUNCIONES UTILITARIAS -----------------------\n",
    "def ensure_sample_index(group, sampling_interval=SAMPLING_INTERVAL):\n",
    "    \"\"\"Si no hay columna de tiempo, crear sample_idx y time_sec.\"\"\"\n",
    "    group = group.copy().reset_index(drop=True)\n",
    "    if 'sample_idx' not in group.columns:\n",
    "        group['sample_idx'] = np.arange(len(group))\n",
    "    if 'time_sec' not in group.columns:\n",
    "        group['time_sec'] = group['sample_idx'] * sampling_interval\n",
    "    return group\n",
    "\n",
    "def compute_run_start_bool(bools, min_run_len=event_steps):\n",
    "    \"\"\"Dada una máscara booleana (True = SpO2 < 90), devuelve array run_start_full de longitud N\n",
    "       con 1 donde comienza una run de longitud >= min_run_len.\"\"\"\n",
    "    N = len(bools)\n",
    "    if N < min_run_len:\n",
    "        return np.zeros(N, dtype=int)\n",
    "    conv = np.convolve(bools.astype(int), np.ones(min_run_len, dtype=int), mode='valid')\n",
    "    starts = (conv == min_run_len).astype(int)   # length = N - min_run_len + 1\n",
    "    run_start_full = np.zeros(N, dtype=int)\n",
    "    run_start_full[:len(starts)] = starts\n",
    "    return run_start_full\n",
    "\n",
    "def extract_aggregated_features(window_df, dyn_cols):\n",
    "    \"\"\"Devuelve un dict con features agregadas para la ventana (por cada dyn_col).\"\"\"\n",
    "    feats = {}\n",
    "    x = window_df[dyn_cols].values  # shape (window_steps, n_dyn)\n",
    "    steps = x.shape[0]\n",
    "    idx = np.arange(steps)\n",
    "    for j, col in enumerate(dyn_cols):\n",
    "        vals = x[:, j]\n",
    "        base_name = col.split('/')[-1]  # e.g. PLETH_SPO2\n",
    "        feats[f'{base_name}_mean'] = float(np.nanmean(vals))\n",
    "        feats[f'{base_name}_std']  = float(np.nanstd(vals))\n",
    "        feats[f'{base_name}_min']  = float(np.nanmin(vals))\n",
    "        feats[f'{base_name}_max']  = float(np.nanmax(vals))\n",
    "        feats[f'{base_name}_last'] = float(vals[-1])\n",
    "        # slope (pendiente) por fit lineal simple\n",
    "        if np.all(np.isfinite(vals)):\n",
    "            try:\n",
    "                slope = np.polyfit(idx, vals, 1)[0]\n",
    "            except np.RankWarning:\n",
    "                slope = 0.0\n",
    "        else:\n",
    "            slope = 0.0\n",
    "        feats[f'{base_name}_slope'] = float(slope)\n",
    "        # para SpO2: % tiempo por debajo de 90 en la ventana\n",
    "        if base_name.upper().find('SPO2') >= 0 or base_name.upper().find('PLETH') >= 0:\n",
    "            feats[f'{base_name}_pct_below_90'] = float(np.mean(vals < 90.0))\n",
    "    return feats\n",
    "\n",
    "# ----------------------- PROCESAR CADA CIRUGÍA -----------------------\n",
    "def process_case_windows(group, dyn_cols, static_cols=STATIC_COLS,\n",
    "                         window_steps=window_steps, horizon_steps=horizon_steps,\n",
    "                         event_steps=event_steps, spo2_col=SPO2_COL):\n",
    "    \"\"\"\n",
    "    Procesa una cirugía (group) y devuelve lista de dicts:\n",
    "      - features agregadas por ventana\n",
    "      - label (0/1)\n",
    "      - caseid, time_end (segundos)\n",
    "    \"\"\"\n",
    "    group = ensure_sample_index(group)\n",
    "    N = len(group)\n",
    "    results = []\n",
    "    if N < window_steps + horizon_steps:\n",
    "        # cirugía demasiado corta para crear ventanas con horizonte completo -> saltar\n",
    "        return results\n",
    "\n",
    "    # arrays veloces\n",
    "    spo2 = group[spo2_col].values\n",
    "    is_low = (spo2 < 90.0)\n",
    "    run_start = compute_run_start_bool(is_low, min_run_len=event_steps)  # length N\n",
    "    # prefix sum para queries rango de run_start\n",
    "    prefix = np.concatenate(([0], run_start.cumsum()))  # length N+1, prefix[k] = sum run_start[:k]\n",
    "\n",
    "    # índices donde la ventana puede terminar: i from window_steps-1 to N-1-horizon_steps (inclusive)\n",
    "    i_start = window_steps - 1\n",
    "    i_end = N - 1 - horizon_steps\n",
    "    window_ends = np.arange(i_start, i_end + 1)\n",
    "\n",
    "    # calc a,b arrays: posibles inicios de run que caben dentro del horizonte\n",
    "    a = window_ends + 1\n",
    "    b = window_ends + horizon_steps - event_steps + 1\n",
    "    # limitar b al máximo índice válido de run_start (N - event_steps)\n",
    "    max_start_index = max(0, N - event_steps)\n",
    "    b = np.minimum(b, max_start_index)\n",
    "\n",
    "    dyn = group[dyn_cols]  # pandas slice\n",
    "\n",
    "    for i_idx, i in enumerate(window_ends):\n",
    "        ai = int(a[i_idx])\n",
    "        bi = int(b[i_idx])\n",
    "        label = 0\n",
    "        if bi >= ai:\n",
    "            # número de run_starts en [ai, bi] = prefix[bi+1] - prefix[ai]\n",
    "            nstarts = int(prefix[bi + 1] - prefix[ai])\n",
    "            if nstarts > 0:\n",
    "                label = 1\n",
    "        # extraer ventana de señales para features\n",
    "        win_start = i - (window_steps - 1)\n",
    "        win_end = i  # inclusive\n",
    "        window_df = dyn.iloc[win_start:win_end + 1]\n",
    "        feats = extract_aggregated_features(window_df, dyn_cols)\n",
    "        # añadir features estáticos (tomados del primer renglón de la cirugía)\n",
    "        static_dict = {}\n",
    "        for s in static_cols:\n",
    "            if s in group.columns:\n",
    "                static_dict[s] = group[s].iloc[0]\n",
    "            else:\n",
    "                static_dict[s] = np.nan\n",
    "        # meta\n",
    "        meta = {\n",
    "            'caseid': group[ID_COL].iloc[0],\n",
    "            'window_end_idx': int(i),\n",
    "            'window_end_time_sec': float(group['time_sec'].iloc[i]),\n",
    "            'label_hypoxemia': int(label)\n",
    "        }\n",
    "        row = {}\n",
    "        row.update(meta)\n",
    "        row.update(static_dict)\n",
    "        row.update(feats)\n",
    "        results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "# ----------------------- PIPELINE PRINCIPAL -----------------------\n",
    "def build_windows_dataframe(df, dyn_prefix=DYN_PREFIX, static_cols=STATIC_COLS,\n",
    "                            save_parquet=True, parquet_path=os.path.join(OUT_DIR, 'windows_aggregated_10min.parquet')):\n",
    "    dyn_cols = [c for c in df.columns if c.startswith(dyn_prefix)]\n",
    "    out_rows = []\n",
    "    grouped = df.groupby(ID_COL)\n",
    "    for caseid, group in tqdm(grouped, total=df[ID_COL].nunique(), desc='Procesando casos'):\n",
    "        rows = process_case_windows(group, dyn_cols, static_cols)\n",
    "        if rows:\n",
    "            out_rows.extend(rows)\n",
    "    windows_df = pd.DataFrame(out_rows)\n",
    "    if save_parquet:\n",
    "        windows_df.to_parquet(parquet_path, index=False)\n",
    "        print(f'Saved windows aggregated to {parquet_path} (n_windows={len(windows_df)})')\n",
    "    return windows_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "372d8fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando casos: 100%|██████████| 910/910 [12:51<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved windows aggregated to windows_output/windows_aggregated_10min.parquet (n_windows=994338)\n",
      "(994338, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>window_end_idx</th>\n",
       "      <th>window_end_time_sec</th>\n",
       "      <th>label_hypoxemia</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>asa</th>\n",
       "      <th>...</th>\n",
       "      <th>VENT_TV_min</th>\n",
       "      <th>VENT_TV_max</th>\n",
       "      <th>VENT_TV_last</th>\n",
       "      <th>VENT_TV_slope</th>\n",
       "      <th>VENT_RR_mean</th>\n",
       "      <th>VENT_RR_std</th>\n",
       "      <th>VENT_RR_min</th>\n",
       "      <th>VENT_RR_max</th>\n",
       "      <th>VENT_RR_last</th>\n",
       "      <th>VENT_RR_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1.201348e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1.201348e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>610.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1.201348e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1.201348e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>1.201348e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  window_end_idx  window_end_time_sec  label_hypoxemia  age sex  \\\n",
       "0       7              59                590.0                0   52   F   \n",
       "1       7              60                600.0                0   52   F   \n",
       "2       7              61                610.0                0   52   F   \n",
       "3       7              62                620.0                0   52   F   \n",
       "4       7              63                630.0                0   52   F   \n",
       "\n",
       "   height  weight   bmi  asa  ...  VENT_TV_min VENT_TV_max VENT_TV_last  \\\n",
       "0   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "1   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "2   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "3   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "4   167.7    62.3  22.2  2.0  ...        893.0       893.0        893.0   \n",
       "\n",
       "  VENT_TV_slope  VENT_RR_mean  VENT_RR_std VENT_RR_min VENT_RR_max  \\\n",
       "0  1.201348e-14           0.0          0.0         0.0         0.0   \n",
       "1  1.201348e-14           0.0          0.0         0.0         0.0   \n",
       "2  1.201348e-14           0.0          0.0         0.0         0.0   \n",
       "3  1.201348e-14           0.0          0.0         0.0         0.0   \n",
       "4  1.201348e-14           0.0          0.0         0.0         0.0   \n",
       "\n",
       "   VENT_RR_last  VENT_RR_slope  \n",
       "0           0.0            0.0  \n",
       "1           0.0            0.0  \n",
       "2           0.0            0.0  \n",
       "3           0.0            0.0  \n",
       "4           0.0            0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------- EJECUCIÓN -----------------------\n",
    "df = pd.read_csv('dataset_fuente_completo2.csv')\n",
    "windows_df4 = build_windows_dataframe(df)\n",
    "print(windows_df4.shape)\n",
    "windows_df4.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeef9dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 994338 entries, 0 to 994337\n",
      "Columns: 101 entries, caseid to VENT_RR_slope\n",
      "dtypes: float64(76), int64(19), object(6)\n",
      "memory usage: 766.2+ MB\n"
     ]
    }
   ],
   "source": [
    "windows_df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c01d7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_hypoxemia\n",
      "0    0.967546\n",
      "1    0.032454\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#VERIFICACIÓN RÁPIDA INICIAL DE HIPOXEMIA\n",
    "print(windows_df4['label_hypoxemia'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54a4ca",
   "metadata": {},
   "source": [
    "El dataset con ventanas que contienen la información de 5 minutos de muestras quedó almaceado en el archivo `windows_aggregated_10min.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747eae6",
   "metadata": {},
   "source": [
    "### Ventanas con datos crudos\n",
    "Quiero probar las segunda opcion de ventanas deslizantes, con ventanas crudas en lugar de features agregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1139a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: generar ventanas de 1 min con DATOS CRUDOS y labels con horizonte 5 min (SpO2 < 90% sostenida 60s)\n",
    "\n",
    "# ----------------------- PARÁMETROS -----------------------\n",
    "SAMPLING_INTERVAL = 10                      # segundos entre muestras\n",
    "WINDOW_SEC = 60\n",
    "HORIZON_SEC = 5 * 60\n",
    "EVENT_SEC = 60\n",
    "\n",
    "window_steps = int(WINDOW_SEC // SAMPLING_INTERVAL)   # = 30\n",
    "horizon_steps = int(HORIZON_SEC // SAMPLING_INTERVAL) # = 30\n",
    "event_steps = int(EVENT_SEC // SAMPLING_INTERVAL)     # = 6\n",
    "\n",
    "SPO2_COL = 'Solar8000/PLETH_SPO2'\n",
    "DYN_PREFIX = 'Solar8000/'\n",
    "ID_COL = 'caseid'\n",
    "\n",
    "# Columnas estáticas\n",
    "STATIC_COLS = [\n",
    "    'age','sex','height','weight','bmi','asa','emop',\n",
    "    'approach','position', 'dltubesize', \n",
    "    'preop_htn', 'preop_dm', 'preop_ecg', 'preop_pft', 'preop_hb',\n",
    "    'intraop_ppf', 'intraop_rbc', 'intraop_ffp',\n",
    "    'intraop_mdz', 'intraop_ftn', 'intraop_rocu', 'intraop_vecu', \n",
    "    'intraop_eph', 'intraop_phe', 'intraop_epi', 'intraop_ca',\n",
    "    'dur_op_seg', 'dur_anest_seg', 'dur_case_seg'\n",
    "]\n",
    "\n",
    "# Carpeta para guardar artefactos\n",
    "OUT_DIR = 'windows_output'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------- FUNCIONES UTILITARIAS -----------------------\n",
    "def ensure_sample_index(group, sampling_interval=SAMPLING_INTERVAL):\n",
    "    \"\"\"Si no hay columna de tiempo, crear sample_idx y time_sec.\"\"\"\n",
    "    group = group.copy().reset_index(drop=True)\n",
    "    if 'sample_idx' not in group.columns:\n",
    "        group['sample_idx'] = np.arange(len(group))\n",
    "    if 'time_sec' not in group.columns:\n",
    "        group['time_sec'] = group['sample_idx'] * sampling_interval\n",
    "    return group\n",
    "\n",
    "def compute_run_start_bool(bools, min_run_len=event_steps):\n",
    "    \"\"\"Dada una máscara booleana (True = SpO2 < 90), devuelve array run_start_full de longitud N\n",
    "       con 1 donde comienza una run de longitud >= min_run_len.\"\"\"\n",
    "    N = len(bools)\n",
    "    if N < min_run_len:\n",
    "        return np.zeros(N, dtype=int)\n",
    "    conv = np.convolve(bools.astype(int), np.ones(min_run_len, dtype=int), mode='valid')\n",
    "    starts = (conv == min_run_len).astype(int)   # length = N - min_run_len + 1\n",
    "    run_start_full = np.zeros(N, dtype=int)\n",
    "    run_start_full[:len(starts)] = starts\n",
    "    return run_start_full\n",
    "\n",
    "\n",
    "# ----------------------- PROCESAR CADA CIRUGÍA -----------------------\n",
    "def process_case_windows(group, dyn_cols, static_cols=STATIC_COLS,\n",
    "                         window_steps=window_steps, horizon_steps=horizon_steps,\n",
    "                         event_steps=event_steps, spo2_col=SPO2_COL):\n",
    "    \"\"\"\n",
    "    Procesa una cirugía (group) y devuelve lista de dicts:\n",
    "      - datos crudos de todas las señales dinámicas (shape: window_steps x n_signals)\n",
    "      - features estáticas\n",
    "      - label (0/1)\n",
    "      - caseid, time_end (segundos)\n",
    "    \"\"\"\n",
    "    group = ensure_sample_index(group)\n",
    "    N = len(group)\n",
    "    results = []\n",
    "    if N < window_steps + horizon_steps:\n",
    "        # cirugía demasiado corta para crear ventanas con horizonte completo -> saltar\n",
    "        return results\n",
    "\n",
    "    # arrays veloces para calcular labels\n",
    "    spo2 = group[spo2_col].values\n",
    "    is_low = (spo2 < 90.0)\n",
    "    run_start = compute_run_start_bool(is_low, min_run_len=event_steps)  # length N\n",
    "    # prefix sum para queries rango de run_start\n",
    "    prefix = np.concatenate(([0], run_start.cumsum()))  # length N+1, prefix[k] = sum run_start[:k]\n",
    "\n",
    "    # índices donde la ventana puede terminar: i from window_steps-1 to N-1-horizon_steps (inclusive)\n",
    "    i_start = window_steps - 1\n",
    "    i_end = N - 1 - horizon_steps\n",
    "    window_ends = np.arange(i_start, i_end + 1)\n",
    "\n",
    "    # calc a,b arrays: posibles inicios de run que caben dentro del horizonte\n",
    "    a = window_ends + 1\n",
    "    b = window_ends + horizon_steps - event_steps + 1\n",
    "    # limitar b al máximo índice válido de run_start (N - event_steps)\n",
    "    max_start_index = max(0, N - event_steps)\n",
    "    b = np.minimum(b, max_start_index)\n",
    "\n",
    "    # Extraer datos estáticos una sola vez (primer renglón de la cirugía)\n",
    "    static_dict = {}\n",
    "    for s in static_cols:\n",
    "        if s in group.columns:\n",
    "            static_dict[s] = group[s].iloc[0]\n",
    "        else:\n",
    "            static_dict[s] = np.nan\n",
    "\n",
    "    for i_idx, i in enumerate(window_ends):\n",
    "        ai = int(a[i_idx])\n",
    "        bi = int(b[i_idx])\n",
    "        label = 0\n",
    "        if bi >= ai:\n",
    "            # número de run_starts en [ai, bi] = prefix[bi+1] - prefix[ai]\n",
    "            nstarts = int(prefix[bi + 1] - prefix[ai])\n",
    "            if nstarts > 0:\n",
    "                label = 1\n",
    "        \n",
    "        # Extraer ventana de datos CRUDOS\n",
    "        win_start = i - (window_steps - 1)\n",
    "        win_end = i  # inclusive\n",
    "        window_data = group[dyn_cols].iloc[win_start:win_end + 1].values  # shape: (window_steps, n_signals)\n",
    "        \n",
    "        # Crear diccionario con los datos crudos\n",
    "        # Formato: cada señal se guarda como array de window_steps valores\n",
    "        raw_data = {}\n",
    "        for j, col in enumerate(dyn_cols):\n",
    "            signal_name = col.split('/')[-1]  # e.g. PLETH_SPO2\n",
    "            raw_data[f'{signal_name}_raw'] = window_data[:, j].tolist()  # convertir a lista para guardar en DataFrame\n",
    "        \n",
    "        # Meta información\n",
    "        meta = {\n",
    "            'caseid': group[ID_COL].iloc[0],\n",
    "            'window_end_idx': int(i),\n",
    "            'window_end_time_sec': float(group['time_sec'].iloc[i]),\n",
    "            'label_hypoxemia': int(label)\n",
    "        }\n",
    "        \n",
    "        # Combinar todo\n",
    "        row = {}\n",
    "        row.update(meta)\n",
    "        row.update(static_dict)\n",
    "        row.update(raw_data)\n",
    "        results.append(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------------- PIPELINE PRINCIPAL -----------------------\n",
    "def build_windows_dataframe_raw(df, dyn_prefix=DYN_PREFIX, static_cols=STATIC_COLS,\n",
    "                            save_parquet=True, parquet_path=os.path.join(OUT_DIR, 'windows_raw_1min.parquet')):\n",
    "    \"\"\"\n",
    "    Construye DataFrame con ventanas de datos crudos.\n",
    "    Cada fila contiene:\n",
    "      - metadata (caseid, window_end_idx, window_end_time_sec)\n",
    "      - features estáticas (age, sex, etc.)\n",
    "      - señales crudas (cada una como lista de window_steps valores)\n",
    "      - label\n",
    "    \"\"\"\n",
    "    dyn_cols = [c for c in df.columns if c.startswith(dyn_prefix)]\n",
    "    out_rows = []\n",
    "    grouped = df.groupby(ID_COL)\n",
    "    \n",
    "    for caseid, group in tqdm(grouped, total=df[ID_COL].nunique(), desc='Procesando casos'):\n",
    "        rows = process_case_windows(group, dyn_cols, static_cols)\n",
    "        if rows:\n",
    "            out_rows.extend(rows)\n",
    "    \n",
    "    windows_df = pd.DataFrame(out_rows)\n",
    "    \n",
    "    if save_parquet:\n",
    "        windows_df.to_parquet(parquet_path, index=False)\n",
    "        print(f'Saved raw windows to {parquet_path} (n_windows={len(windows_df)})')\n",
    "        print(f'Columnas: {list(windows_df.columns)}')\n",
    "        print(f'Shape por señal: ({window_steps} timesteps)')\n",
    "    \n",
    "    return windows_df\n",
    "\n",
    "\n",
    "# ----------------------- FUNCIÓN AUXILIAR PARA RECUPERAR DATOS -----------------------\n",
    "def get_window_arrays(windows_df, dyn_prefix=DYN_PREFIX):\n",
    "    \"\"\"\n",
    "    Convierte el DataFrame de ventanas con datos crudos de vuelta a arrays numpy.\n",
    "    \n",
    "    Returns:\n",
    "        X: array shape (n_windows, window_steps, n_signals) - datos de señales\n",
    "        y: array shape (n_windows,) - labels\n",
    "        static_features: DataFrame con features estáticas\n",
    "        metadata: DataFrame con metadata (caseid, time, etc.)\n",
    "    \"\"\"\n",
    "    # Identificar columnas de señales crudas\n",
    "    raw_cols = [c for c in windows_df.columns if c.endswith('_raw')]\n",
    "    \n",
    "    # Convertir listas a arrays\n",
    "    X = np.array([windows_df[col].tolist() for col in raw_cols])  # shape: (n_signals, n_windows, window_steps)\n",
    "    X = np.transpose(X, (1, 2, 0))  # shape: (n_windows, window_steps, n_signals)\n",
    "    \n",
    "    # Labels\n",
    "    y = windows_df['label_hypoxemia'].values\n",
    "    \n",
    "    # Features estáticas\n",
    "    static_features = windows_df[STATIC_COLS]\n",
    "    \n",
    "    # Metadata\n",
    "    meta_cols = ['caseid', 'window_end_idx', 'window_end_time_sec']\n",
    "    metadata = windows_df[meta_cols]\n",
    "    \n",
    "    return X, y, static_features, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75962e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando casos: 100%|██████████| 910/910 [02:53<00:00,  5.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw windows to windows_output/windows_raw_1min.parquet (n_windows=1043478)\n",
      "Columnas: ['caseid', 'window_end_idx', 'window_end_time_sec', 'label_hypoxemia', 'age', 'sex', 'height', 'weight', 'bmi', 'asa', 'emop', 'approach', 'position', 'dltubesize', 'preop_htn', 'preop_dm', 'preop_ecg', 'preop_pft', 'preop_hb', 'intraop_ppf', 'intraop_rbc', 'intraop_ffp', 'intraop_mdz', 'intraop_ftn', 'intraop_rocu', 'intraop_vecu', 'intraop_eph', 'intraop_phe', 'intraop_epi', 'intraop_ca', 'dur_op_seg', 'dur_anest_seg', 'dur_case_seg', 'ETCO2_raw', 'FEO2_raw', 'FIO2_raw', 'HR_raw', 'INCO2_raw', 'RR_CO2_raw', 'PLETH_SPO2_raw', 'PLETH_HR_raw', 'VENT_PIP_raw', 'VENT_TV_raw', 'VENT_RR_raw']\n",
      "Shape por señal: (6 timesteps)\n",
      "(1043478, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>window_end_idx</th>\n",
       "      <th>window_end_time_sec</th>\n",
       "      <th>label_hypoxemia</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>asa</th>\n",
       "      <th>...</th>\n",
       "      <th>FEO2_raw</th>\n",
       "      <th>FIO2_raw</th>\n",
       "      <th>HR_raw</th>\n",
       "      <th>INCO2_raw</th>\n",
       "      <th>RR_CO2_raw</th>\n",
       "      <th>PLETH_SPO2_raw</th>\n",
       "      <th>PLETH_HR_raw</th>\n",
       "      <th>VENT_PIP_raw</th>\n",
       "      <th>VENT_TV_raw</th>\n",
       "      <th>VENT_RR_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[65.0, 68.0, 67.0, 67.0, 67.0, 74.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[61.0, 61.0, 65.0, 65.0, 65.0, 65.0]</td>\n",
       "      <td>[99.0, 99.0, 101.0, 101.0, 101.0, 101.0]</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0]</td>\n",
       "      <td>[893.0, 893.0, 893.0, 893.0, 893.0, 893.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[68.0, 67.0, 67.0, 67.0, 74.0, 69.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[61.0, 65.0, 65.0, 65.0, 65.0, 65.0]</td>\n",
       "      <td>[99.0, 101.0, 101.0, 101.0, 101.0, 101.0]</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0]</td>\n",
       "      <td>[893.0, 893.0, 893.0, 893.0, 893.0, 893.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[67.0, 67.0, 67.0, 74.0, 69.0, 68.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[65.0, 65.0, 65.0, 65.0, 65.0, 65.0]</td>\n",
       "      <td>[101.0, 101.0, 101.0, 101.0, 101.0, 101.0]</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0]</td>\n",
       "      <td>[893.0, 893.0, 893.0, 893.0, 893.0, 893.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[67.0, 67.0, 74.0, 69.0, 68.0, 69.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[65.0, 65.0, 65.0, 65.0, 65.0, 62.0]</td>\n",
       "      <td>[101.0, 101.0, 101.0, 101.0, 101.0, 101.0]</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0]</td>\n",
       "      <td>[893.0, 893.0, 893.0, 893.0, 893.0, 893.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>167.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[21.0, 21.0, 21.0, 21.0, 21.0, 21.0]</td>\n",
       "      <td>[67.0, 74.0, 69.0, 68.0, 69.0, 64.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[65.0, 65.0, 65.0, 65.0, 62.0, 59.0]</td>\n",
       "      <td>[101.0, 101.0, 101.0, 101.0, 101.0, 94.0]</td>\n",
       "      <td>[4.0, 4.0, 4.0, 4.0, 4.0, 4.0]</td>\n",
       "      <td>[893.0, 893.0, 893.0, 893.0, 893.0, 893.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  window_end_idx  window_end_time_sec  label_hypoxemia  age sex  \\\n",
       "0       7               5                 50.0                1   52   F   \n",
       "1       7               6                 60.0                1   52   F   \n",
       "2       7               7                 70.0                1   52   F   \n",
       "3       7               8                 80.0                1   52   F   \n",
       "4       7               9                 90.0                1   52   F   \n",
       "\n",
       "   height  weight   bmi  asa  ...                              FEO2_raw  \\\n",
       "0   167.7    62.3  22.2  2.0  ...  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]   \n",
       "1   167.7    62.3  22.2  2.0  ...  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]   \n",
       "2   167.7    62.3  22.2  2.0  ...  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]   \n",
       "3   167.7    62.3  22.2  2.0  ...  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]   \n",
       "4   167.7    62.3  22.2  2.0  ...  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]   \n",
       "\n",
       "                               FIO2_raw                                HR_raw  \\\n",
       "0  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]  [65.0, 68.0, 67.0, 67.0, 67.0, 74.0]   \n",
       "1  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]  [68.0, 67.0, 67.0, 67.0, 74.0, 69.0]   \n",
       "2  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]  [67.0, 67.0, 67.0, 74.0, 69.0, 68.0]   \n",
       "3  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]  [67.0, 67.0, 74.0, 69.0, 68.0, 69.0]   \n",
       "4  [21.0, 21.0, 21.0, 21.0, 21.0, 21.0]  [67.0, 74.0, 69.0, 68.0, 69.0, 64.0]   \n",
       "\n",
       "                        INCO2_raw                      RR_CO2_raw  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                         PLETH_SPO2_raw  \\\n",
       "0  [61.0, 61.0, 65.0, 65.0, 65.0, 65.0]   \n",
       "1  [61.0, 65.0, 65.0, 65.0, 65.0, 65.0]   \n",
       "2  [65.0, 65.0, 65.0, 65.0, 65.0, 65.0]   \n",
       "3  [65.0, 65.0, 65.0, 65.0, 65.0, 62.0]   \n",
       "4  [65.0, 65.0, 65.0, 65.0, 62.0, 59.0]   \n",
       "\n",
       "                                 PLETH_HR_raw                    VENT_PIP_raw  \\\n",
       "0    [99.0, 99.0, 101.0, 101.0, 101.0, 101.0]  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0]   \n",
       "1   [99.0, 101.0, 101.0, 101.0, 101.0, 101.0]  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0]   \n",
       "2  [101.0, 101.0, 101.0, 101.0, 101.0, 101.0]  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0]   \n",
       "3  [101.0, 101.0, 101.0, 101.0, 101.0, 101.0]  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0]   \n",
       "4   [101.0, 101.0, 101.0, 101.0, 101.0, 94.0]  [4.0, 4.0, 4.0, 4.0, 4.0, 4.0]   \n",
       "\n",
       "                                  VENT_TV_raw                     VENT_RR_raw  \n",
       "0  [893.0, 893.0, 893.0, 893.0, 893.0, 893.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1  [893.0, 893.0, 893.0, 893.0, 893.0, 893.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2  [893.0, 893.0, 893.0, 893.0, 893.0, 893.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [893.0, 893.0, 893.0, 893.0, 893.0, 893.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4  [893.0, 893.0, 893.0, 893.0, 893.0, 893.0]  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------- EJECUCIÓN -----------------------\n",
    "df = pd.read_csv('dataset_fuente_completo2.csv')\n",
    "windows_df5 = build_windows_dataframe_raw(df)\n",
    "print(windows_df5.shape)\n",
    "windows_df5.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf8d4cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_hypoxemia\n",
      "0    0.967905\n",
      "1    0.032095\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#VERIFICACIÓN RÁPIDA INICIAL DE HIPOXEMIA\n",
    "print(windows_df5['label_hypoxemia'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f3681",
   "metadata": {},
   "source": [
    "Tengo un dataset en el que la información de los datos crudos de cada ventana se almacena en listas. ESto quedó guardado en el archivo `windows_raw_1min.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f228c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# ESTRATEGIAS PARA TRABAJAR CON VENTANAS DE DATOS CRUDOS EN ML\n",
    "# =====================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# =====================================================================\n",
    "# OPCIÓN 1: Modelos de secuencias (LSTM, Transformers, CNN1D)\n",
    "# =====================================================================\n",
    "# Mejor para: Capturar patrones temporales complejos\n",
    "# Formato necesario: (n_samples, timesteps, features)\n",
    "\n",
    "def prepare_for_sequence_models(windows_df, dyn_prefix='Solar8000/'):\n",
    "    \"\"\"\n",
    "    Convierte DataFrame con listas a arrays 3D para modelos de secuencias.\n",
    "    \n",
    "    Returns:\n",
    "        X_seq: (n_windows, window_steps, n_signals) - para LSTM/CNN1D\n",
    "        X_static: (n_windows, n_static_features) - features estáticas\n",
    "        y: (n_windows,) - labels\n",
    "    \"\"\"\n",
    "    # Identificar columnas\n",
    "    raw_cols = [c for c in windows_df.columns if c.endswith('_raw')]\n",
    "    static_cols = ['age','sex','height','weight','bmi','asa','emop',\n",
    "                   'approach','position','dltubesize','preop_htn','preop_dm']\n",
    "    \n",
    "    # Convertir señales temporales a array 3D\n",
    "    X_seq = np.array([windows_df[col].tolist() for col in raw_cols])\n",
    "    X_seq = np.transpose(X_seq, (1, 2, 0))  # (n_windows, timesteps, n_signals)\n",
    "    \n",
    "    # Features estáticas (2D)\n",
    "    X_static = windows_df[static_cols].fillna(0).values\n",
    "    \n",
    "    # Labels\n",
    "    y = windows_df['label_hypoxemia'].values\n",
    "    \n",
    "    return X_seq, X_static, y\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# OPCIÓN 2: Aplanar datos (flatten) para modelos tradicionales\n",
    "# =====================================================================\n",
    "# Mejor para: RandomForest, XGBoost, Logistic Regression\n",
    "# Formato necesario: (n_samples, total_features)\n",
    "\n",
    "def prepare_flattened(windows_df):\n",
    "    \"\"\"\n",
    "    Aplana todas las series temporales en un vector 1D por ventana.\n",
    "    \n",
    "    Si tienes 30 timesteps y 5 señales = 150 features temporales\n",
    "    + features estáticas = vector largo por ventana\n",
    "    \"\"\"\n",
    "    raw_cols = [c for c in windows_df.columns if c.endswith('_raw')]\n",
    "    static_cols = ['age','sex','height','weight','bmi','asa','emop',\n",
    "                   'approach','position','dltubesize']\n",
    "    \n",
    "    # Aplanar señales temporales\n",
    "    flattened_lists = []\n",
    "    feature_names = []\n",
    "    \n",
    "    for col in raw_cols:\n",
    "        signal_name = col.replace('_raw', '')\n",
    "        # Convertir cada lista en múltiples columnas: signal_t0, signal_t1, ...\n",
    "        arr = np.array(windows_df[col].tolist())  # (n_windows, timesteps)\n",
    "        flattened_lists.append(arr)\n",
    "        feature_names.extend([f'{signal_name}_t{i}' for i in range(arr.shape[1])])\n",
    "    \n",
    "    X_temporal = np.hstack(flattened_lists)  # (n_windows, timesteps * n_signals)\n",
    "    \n",
    "    # Agregar features estáticas\n",
    "    X_static = windows_df[static_cols].fillna(0).values\n",
    "    static_names = static_cols\n",
    "    \n",
    "    # Combinar todo\n",
    "    X_flat = np.hstack([X_temporal, X_static])\n",
    "    all_feature_names = feature_names + static_names\n",
    "    \n",
    "    y = windows_df['label_hypoxemia'].values\n",
    "    \n",
    "    return X_flat, y, all_feature_names\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# OPCIÓN 3: Feature engineering manual (mejor de ambos mundos)\n",
    "# =====================================================================\n",
    "# Mejor para: Cuando quieres control sobre las features\n",
    "# Creas features agregadas + algunas features temporales clave\n",
    "\n",
    "def prepare_engineered_features(windows_df):\n",
    "    \"\"\"\n",
    "    Combina estadísticas agregadas con algunas features temporales clave.\n",
    "    Más eficiente que flatten completo, más interpretable que LSTM.\n",
    "    \"\"\"\n",
    "    raw_cols = [c for c in windows_df.columns if c.endswith('_raw')]\n",
    "    static_cols = ['age','sex','height','weight','bmi']\n",
    "    \n",
    "    features = []\n",
    "    feature_names = []\n",
    "    \n",
    "    # Features estáticas\n",
    "    X_static = windows_df[static_cols].fillna(0).values\n",
    "    features.append(X_static)\n",
    "    feature_names.extend(static_cols)\n",
    "    \n",
    "    # Para cada señal, extraer features agregadas + últimos valores\n",
    "    for col in raw_cols:\n",
    "        signal_name = col.replace('_raw', '')\n",
    "        arr = np.array(windows_df[col].tolist())  # (n_windows, timesteps)\n",
    "        \n",
    "        # Estadísticas agregadas\n",
    "        feat_dict = {\n",
    "            f'{signal_name}_mean': np.nanmean(arr, axis=1),\n",
    "            f'{signal_name}_std': np.nanstd(arr, axis=1),\n",
    "            f'{signal_name}_min': np.nanmin(arr, axis=1),\n",
    "            f'{signal_name}_max': np.nanmax(arr, axis=1),\n",
    "            f'{signal_name}_range': np.nanmax(arr, axis=1) - np.nanmin(arr, axis=1),\n",
    "        }\n",
    "        \n",
    "        # Últimos 5 valores (tendencia reciente)\n",
    "        for i in range(5):\n",
    "            feat_dict[f'{signal_name}_last_{i+1}'] = arr[:, -(i+1)]\n",
    "        \n",
    "        # Pendiente (trend)\n",
    "        timesteps = arr.shape[1]\n",
    "        x_vals = np.arange(timesteps)\n",
    "        slopes = []\n",
    "        for row in arr:\n",
    "            if np.all(np.isfinite(row)):\n",
    "                slope = np.polyfit(x_vals, row, 1)[0]\n",
    "            else:\n",
    "                slope = 0.0\n",
    "            slopes.append(slope)\n",
    "        feat_dict[f'{signal_name}_slope'] = np.array(slopes)\n",
    "        \n",
    "        # Agregar todas las features de esta señal\n",
    "        for fname, fvals in feat_dict.items():\n",
    "            features.append(fvals.reshape(-1, 1))\n",
    "            feature_names.append(fname)\n",
    "    \n",
    "    X_engineered = np.hstack(features)\n",
    "    y = windows_df['label_hypoxemia'].values\n",
    "    \n",
    "    return X_engineered, y, feature_names\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# OPCIÓN 4: Guardar en formato optimizado para ML\n",
    "# =====================================================================\n",
    "\n",
    "def save_in_ml_format(windows_df, output_dir='ml_ready_data'):\n",
    "    \"\"\"\n",
    "    Guarda los datos en formatos listos para ML:\n",
    "    - Arrays numpy para modelos de secuencias\n",
    "    - CSV aplanado para modelos tradicionales\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Formato para secuencias (LSTM, etc)\n",
    "    X_seq, X_static, y = prepare_for_sequence_models(windows_df)\n",
    "    np.save(f'{output_dir}/X_sequences.npy', X_seq)\n",
    "    np.save(f'{output_dir}/X_static.npy', X_static)\n",
    "    np.save(f'{output_dir}/y_labels.npy', y)\n",
    "    \n",
    "    # Formato aplanado (RF, XGBoost, etc)\n",
    "    X_flat, y_flat, feature_names = prepare_flattened(windows_df)\n",
    "    flat_df = pd.DataFrame(X_flat, columns=feature_names)\n",
    "    flat_df['label'] = y_flat\n",
    "    flat_df.to_csv(f'{output_dir}/flattened_data.csv', index=False)\n",
    "    \n",
    "    # Metadata\n",
    "    metadata = windows_df[['caseid', 'window_end_idx', 'window_end_time_sec']]\n",
    "    metadata.to_csv(f'{output_dir}/metadata.csv', index=False)\n",
    "    \n",
    "    print(f\"✓ Guardado en {output_dir}/\")\n",
    "    print(f\"  - X_sequences.npy: {X_seq.shape}\")\n",
    "    print(f\"  - X_static.npy: {X_static.shape}\")\n",
    "    print(f\"  - flattened_data.csv: {flat_df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vitaldb_env_nuevo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
